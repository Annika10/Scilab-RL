name: 'hac'

# Steps per level from highest to lowest, separated by comma. -1 indicates that a layer's timescale is determined
# from the environment's predefined steps and the other time scales.
time_scales:
  - -1
  - 7

# layer classes for the algorithm
layer_classes:
  - sacvg
  - sacvg

# The learning rates of the layers. From highest to lowest layer.
learning_rates:
    - 0.0018
    - 0.003

verbose: True

# 'future', 'future2', 'final', 'episode', 'rndend', 'rndend2'
goal_selection_strategy: 'rndend'

n_sampled_goal: 6

# number of steps in each layer after which to train.
# 0 sets the training frequency to once per episode.
train_freq: 0

# The number of training batches per episode. 0 sets training batches to number of
# actions executed since last training in each layer, which effectively means that n_train_batches=n_train_freq.
n_train_batches: 0

# The number of transitions in each layer required to start NN training.
learning_starts: 100

# Whether to use action replay
use_action_replay: 1

# Number of successive successful steps to stop an episode early when
# the (sub-)goal has been achieved. 0 disables early stopping.
ep_early_done_on_succ: 1

# Whether to consider an episode as done *in hindsight* during goal replay
# if the hindsight goal has been achieved. This is important e.g. in SAC,
# where the discounted expected return is set to 0 of an episode is done.
# Only relevant if set_fut_ret_zero_if_done = 1.
hindsight_sampling_done_if_success: 0

# Whether to set the future expected return to 0 if an episode is
# done when computing the TD q value.
set_fut_ret_zero_if_done: 0

# The percentage of subgoals to test.
subgoal_test_perc: 0.1



