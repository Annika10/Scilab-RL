#############################################################
## The performance for this environment is still quite bad ##
## Maybe works better with single layer approach           ##
#############################################################

performance_testing_conditions:
  # In 2 out of 3 tests, the test/success rate should be at least 0.9 after 200000 steps.

  total_runs: 3 # How many runs in total:

  succ_runs: 2 # This number of runs should meet the conditions:

  eval_columns: test/success_rate # This is what we evaluate to determine success. Will use this to override the \'early_stop_data_column\' parameter of main.yaml

  eval_value: 0.05 # This is the value we determine for success. Will use this to determine and override the \'early_stop_threshold\' parameter of main.yaml

  max_steps: 200000 # This is the time limit for checking the success. Will use this and the \'eval_after_n_steps\' parameter of main.yaml to determine the n_epochs parameter in main.yaml.


main_overrides: # These are the overrides for main.yaml
  algorithm: hac
  env: 'Blocks-o1-gripper_above-v1'

  # The n last epochs over which to average for determining early stopping condition.
  early_stop_last_n: 4

alg_overrides:
  # number of hindisght goals.
  n_sampled_goal: 7

  # Whether to consider an episode as done *in hindsight* during goal replay
  # if the hindsight goal has been achieved. This is important e.g. in SAC,
  # where the discounted expected return is set to 0 of an episode is done.
  # Only relevant if set_fut_ret_zero_if_done = 1.
  hindsight_sampling_done_if_success: 1

hydra:
  sweeper:
    study_name: hac_2_layer_ButtonUnlock-o1-v1
    storage: sqlite:///hac_2_layer_ButtonUnlock-o1-v1.db
    search_space:
      algorithm.learning_rates.0:
        type: float
        low: 6e-4
        high: 3e-2
        log: true
#
      algorithm.learning_rates.1:
        type: float
        low: 6e-4
        high: 3e-2
        log: true
#
      algorithm.n_sampled_goal:
        type: int
        low: 1
        high: 8
        step: 1
#
      algorithm.subgoal_test_perc:
        type: float
        low: 0.0
        high: 0.7
        step: 0.1

      algorithm.goal_selection_strategy:
        type: categorical
        choices:
          - future
          - future2
          - rndend
          - rndend2

      algorithm.use_action_replay:
        type: categorical
        choices:
          - 1
          - 0

      algorithm.ep_early_done_on_succ:
        type: int
        low: 0
        high: 2
        step: 1

      algorithm.hindsight_sampling_done_if_success:
        type: categorical
        choices:
          - 1
          - 0

      algorithm.set_fut_ret_zero_if_done:
        type: categorical
        choices:
          - 1
          - 0