performance_testing_conditions:

  # In 2 out of 3 tests, the test/success rate should be at least 0.9 after 100000 steps.

  total_runs: 3 # How many runs in total:

  succ_runs: 2 # This number of runs should meet the conditions:

  eval_columns: test/success_rate # This is what we evaluate to determine success. Will use this to override the \'early_stop_data_column\' parameter of main.yaml

  eval_value: 0.9 # This is the value we determine for success. Will use this to determine and override the \'early_stop_threshold\' parameter of main.yaml

  max_steps: 14000 # This is the time limit for checking the success. Will use this and the \'eval_after_n_steps\' parameter of main.yaml to determine the n_epochs parameter in main.yaml.


main_overrides: # These are the overrides for main.yaml

  algorithm: her
  env: 'FetchReach-v1'
  seed: 0

  # layer classes for the algorithm
  layer_classes:
    - sac

  # The number of training steps after which to evaluate the policy.
  eval_after_n_steps: 2000

  # The number of testing rollouts.
  n_test_rollouts: 10

  # Max. number of tries for this training config.
  max_try_idx: 399

  # Index for first try.
  try_start_idx: 100

  # The n last epochs over which to average for determining early stopping condition.
  early_stop_last_n: 4

  # The data column on which early stopping is based.
  early_stop_data_column: 'test/success_rate'

    # The number of steps after which to save the model.
  save_model_freq: 0

alg_overrides:

  verbose: true

hydra:
  sweeper:
    study_name: hac_1_layer_FetchReach-v1
    storage: sqlite:///hac_1_layer_FetchReach.db
    search_space:
      algorithm.learning_rates.0:
        type: float
        low: 6e-4
        high: 3e-2
        log: true
#
      algorithm.n_sampled_goal:
        type: int
        low: 1
        high: 8
        step: 1
#
      algorithm.subgoal_test_perc:
        type: float
        low: 0.0
        high: 0.7
        step: 0.1

      algorithm.goal_selection_strategy:
        type: categorical
        choices:
          - future
          - future2
          - rndend
          - rndend2

      algorithm.use_action_replay:
        type: categorical
        choices:
          - 1
          - 0

      algorithm.ep_early_done_on_succ:
        type: int
        low: 0
        high: 2
        step: 1

      algorithm.hindsight_sampling_done_if_success:
        type: categorical
        choices:
          - 1
          - 0

      algorithm.set_fut_ret_zero_if_done:
        type: categorical
        choices:
          - 1
          - 0